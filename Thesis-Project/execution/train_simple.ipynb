{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true,
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project')  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/.env')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import BCELoss, BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from data_handling.data_augmentation import VideoTransform\n",
    "from data_handling.video_dataset import VideoDataset\n",
    "from model.violence_detection_model import ViolenceDetectionModel\n",
    "from utils import collate_fn_pad\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"lr\": 0.0008279,\n",
    "    \"epochs\": 1,\n",
    "    \"factor\": 0.02839,\n",
    "    \"batch\": 20,\n",
    "    \"n_folds\": 4,\n",
    "    \"step_size\": 1\n",
    "}\n",
    "\n",
    "def train():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"device: {}\".format(device))\n",
    "\n",
    "    print(\"set transforms for each dataset\")\n",
    "    hf_transforms = VideoTransform(dataset=\"RWF-2000\", json_file=\"augmentation_values.json\")\n",
    "\n",
    "    print(\"initialize datasets\")\n",
    "    hf_dataset = VideoDataset(dataset=\"RWF-300\", transformations=hf_transforms)\n",
    "    \n",
    "    # helper list for calculating the final val_loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for dataset in [hf_dataset]:\n",
    "        print(\"dataset {}\".format(dataset.dataset))\n",
    "\n",
    "        for n, fold in enumerate(dataset.k_fold(n_folds=config[\"n_folds\"])):\n",
    "            print(\"fold {}\".format(n))\n",
    "            dataloader = data.DataLoader(fold, batch_size=config[\"batch\"], collate_fn=collate_fn_pad, shuffle=True, num_workers=2)\n",
    "\n",
    "            print(\"create model\")\n",
    "            vd_model = ViolenceDetectionModel(json_file=\"model_settings.json\")\n",
    "            vd_model = vd_model.to(device)\n",
    "\n",
    "            criterion = BCEWithLogitsLoss()\n",
    "            optimizer = Adam(params=vd_model.parameters(), lr=config[\"lr\"])\n",
    "            scheduler = StepLR(optimizer=optimizer, step_size=config[\"step_size\"], gamma=config[\"factor\"])\n",
    "            scaler = GradScaler()\n",
    "\n",
    "            accumulation_steps = 5\n",
    "\n",
    "            # track losses per batch in training along epochs\n",
    "            losses_per_batch = np.array([])\n",
    "\n",
    "            for epoch in range(config[\"epochs\"]):\n",
    "                print(\"epoch {}\".format(epoch))\n",
    "\n",
    "                # ------------train------------\n",
    "                print(\"training\")\n",
    "\n",
    "                vd_model.train()\n",
    "                # use training part of dataset\n",
    "                fold.flag = False\n",
    "\n",
    "                # track loss for entire train dataset\n",
    "                cumulating_loss = 0.0\n",
    "                plot_loss = 0\n",
    "\n",
    "                print(len(fold))\n",
    "                print(len(dataloader))\n",
    "                for i, batch in enumerate(dataloader):\n",
    "                    print(\"batch\")\n",
    "\n",
    "                    videos, labels, lengths = batch\n",
    "                    videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "                    with autocast():\n",
    "                        outputs = vd_model(videos, lengths)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss = loss / accumulation_steps\n",
    "                        \n",
    "                    # loss.backward() \n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    plot_loss += loss.cpu().item()\n",
    "                    \n",
    "                    if ((i + 1) % accumulation_steps == 0) or (i + 1 == len(dataloader)):\n",
    "                        # optimizer.step()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad()\n",
    "                        print(\"opt\")\n",
    "                        losses_per_batch = np.append(losses_per_batch, plot_loss)\n",
    "                        cumulating_loss += plot_loss\n",
    "                        plot_loss = 0\n",
    "\n",
    "                    del videos, labels\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                # log the cumulating train loss to wandb\n",
    "                avg_loss = cumulating_loss / len(dataloader)\n",
    "                train_losses.append(avg_loss)\n",
    "                print(\"train loss: {}\".format(avg_loss))\n",
    "\n",
    "                scheduler.step()\n",
    "                # ------------val------------\n",
    "                print(\"evaluating\")\n",
    "\n",
    "                vd_model.eval()\n",
    "                fold.flag = True\n",
    "\n",
    "                # lists for tracking loss and f1 for the entire val dataset\n",
    "                cumulating_loss = 0.0\n",
    "                cumulating_outputs = []\n",
    "                cumulating_labels = []\n",
    "\n",
    "                print(len(fold))\n",
    "                print(len(dataloader))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for batch in dataloader:\n",
    "                        print(\"batch\")\n",
    "                        videos, labels, lengths = batch\n",
    "                        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "                        with autocast():\n",
    "                            outputs = vd_model(videos, lengths)\n",
    "                            loss = criterion(outputs, labels)\n",
    "\n",
    "                            cumulating_loss += loss.cpu().item()\n",
    "                            cumulating_outputs.extend(outputs.cpu().tolist())\n",
    "                            cumulating_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "                        del videos, labels\n",
    "                        gc.collect()\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                avg_loss = cumulating_loss / len(dataloader)\n",
    "                print(\"val loss: {}\".format(avg_loss))\n",
    "\n",
    "                val_losses.append(avg_loss)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "            # Plot batch losses on the first subplot\n",
    "            ax[0].plot(losses_per_batch, label=\"Loss per batch\")\n",
    "            ax[0].set_title('Batch Losses')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_ylabel('Loss')\n",
    "            ax[0].legend()\n",
    "\n",
    "            # Plot train and validation losses on the second subplot\n",
    "            ax[1].plot(np.arange(config[\"epochs\"]), train_losses, label='Train Loss')\n",
    "            ax[1].plot(np.arange(config[\"epochs\"]), val_losses, label='Validation Loss')\n",
    "            ax[1].set_title('Training and Validation Losses')\n",
    "            ax[1].set_xlabel('Epochs')\n",
    "            ax[1].set_ylabel('Loss')\n",
    "            ax[1].legend()\n",
    "\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            \n",
    "            torch.save(vd_model.state_dict(), 'model_weights.pth')\n",
    "            break  # fold       \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1ef3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: urr7b8k9\n",
      "Sweep URL: https://wandb.ai/soniamatei/vd_model_training/sweeps/urr7b8k9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g4xf6r5u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfactor: 0.006869515440405294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002407053645211852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_folds: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstep_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttreshold: 0.5\n",
      "initialize wandb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msoniamatei\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/execution/wandb/run-20240530_115729-g4xf6r5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgraceful-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training/sweeps/urr7b8k9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training/runs/g4xf6r5u\u001b[0m\n",
      "device: cuda\n",
      "set transforms for each dataset\n",
      "initialize datasets\n",
      "dataset HockeyFights\n",
      "fold 0\n",
      "create model\n",
      "/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "epoch 0\n",
      "training\n",
      "750\n",
      "32\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "evaluating\n",
      "250\n",
      "11\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "epoch 1\n",
      "training\n",
      "750\n",
      "32\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "evaluating\n",
      "250\n",
      "11\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          epoch ▁▁██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    fold_0_HockeyFights_f1score ▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_0_HockeyFights_train_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   fold_0_HockeyFights_val_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mean_f1_score ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mean_val_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    fold_0_HockeyFights_f1score 0.67021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fold_0_HockeyFights_train_loss 0.73835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   fold_0_HockeyFights_val_loss 0.75809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mean_f1_score 0.67021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  mean_val_loss 0.92783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgraceful-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training/runs/g4xf6r5u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240530_115729-g4xf6r5u/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r4bcvic3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfactor: 0.07064977367965193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.050076175705496065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_folds: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstep_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttreshold: 0.5\n",
      "initialize wandb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/execution/wandb/run-20240530_120559-r4bcvic3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training/sweeps/urr7b8k9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/soniamatei/vd_model_training/runs/r4bcvic3\u001b[0m\n",
      "device: cuda\n",
      "set transforms for each dataset\n",
      "initialize datasets\n",
      "dataset HockeyFights\n",
      "fold 0\n",
      "create model\n",
      "/home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "epoch 0\n",
      "training\n",
      "750\n",
      "32\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "^C\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
      "initialize wandb\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    }
   ],
   "source": [
    "! python /home/sonia2oo2soia/projects/Thesis-Project/Thesis-Project/execution/train.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
